---
title: "In Search of Basu's Elephants"
author: "Merlise Clyde"
subtitle: |
 | Conference Honoring Basu and Bahadur
 | Theory and Foundations of Statistics in the Era of Big Data
institute: "Duke University"
date: "4/21/2024"
format: 
  revealjs:
    theme: [simple, custom.scss]
    slide-number: true
    incremental: true
    scrollable: false
    controls: true
    fragments: true
    preview-links: auto
    smaller: true
    logo: ../../img/Dukelogo.jpg
    chalkboard: 
      boardmarker-width: 1
      chalk-width: 2
      chalk-effect: 0
    embed-resources: false
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"    
editor: 
  markdown: 
    wrap: 72
execute: 
  echo: false
number-sections: false
---



```{r}
#| echo: false
library(BAS)
```


## Basu's Elephants


{{< include macros.qmd >}}


:::: {.columns}

::: {.column width="60%"}
Circus Owner plans to ship his 50 elephants

- needs an approximate total weight of the 50 elephants
- Sambo is a typical elephant of average weight
- decides to take 50 $\times$ Sambo's weight as an estimate of the total weight
:::

::: {.column width="40%"}
![](img/circus-ship.jpeg){width="70%"}
:::

::::

## Sampling Design 

:::: {.columns}

::: {.column width="60%"}
Circus Statistician is shocked!

- we need an approximate sampling design to create an unbiased estimator
- sample Sambo with probability $99/100$
- the rest of the elephants with probability $1/4900$

:::

::: {.column width="40%"}
![](img/shocked-statistician.png){width="70%"}
:::

::::
## Unbiased Estimation

:::: {.columns}

::: {.column width="60%"}

Everyone was happy when Sambo was selected
- Circus Owner proposes using $50 \times$ Sambo's current weight
- Circus Statistician insists on using the Horvitz-Thompson Estimator
   - unique hyperadmissible estimator in the class of all generalized polynomial unbiased estimators!
- HT estimate is Sambo's weight $\div$ probability Sambo was selected  -or- W $\times 100/99$
- BUt what if the largest elephant Jumbo had been selected?
- HT would lead to Jumbo's weight $\times 4900/1$!
- and thus the Circus statistician need a new job!
:::

::: {.column width="40%"}
![](img/basu-elephant.png){width="70%"}
:::

::::
## Variable Selection

Importance sampling - approx to posterior in Orthogonal design.  (conditionally indpendent; RB possible )

Ergodic Averages versus using acumulated knowledge of sampled marginals.  (renormalized vs MC freq)

Harmonic Mean equivalent to Hansen Huriwtz estimator in PPS sampling (samping basaed on posterior of models)  

Let $\rho_i$ be the probability of selecting $M_i$
Estimate of Normalizing constant 
$T = \sum_i^N m(\gamma_i)$ 

Models samples from $\rho_i$ using the Hansen-Huriwtz estimator

$$
\hat{T} = \frac{1}{n}\sum_i^n \frac{m(\gamma_i)}{\rho_i}
$$
If we have "perfect" samples from the posterior then $$\rho_i = m(\gamma_i)/T$$, but since $T$ is unknown, we can apply the ratio estimator
$$
\hat{T} = \frac{\frac1 n \sum_i^n \frac{m(\gamma_i)}{\rho_i}}{ \frac1 n \sum_i^n \frac{1}{\rho_i}} =  \left[\frac 1 n  \sum_i \frac{1}{m(\gamma_i)} \right]^{-1}
$$
which is the harmonic mean estimator.  While unbiased is highly unstable

Express as a function of the Unique values
$$
\hat{T} = \frac{ \sum_i^N n_i\frac{m(\gamma_i)}{\rho_i}}{ \frac1 n \sum_i^n \frac{n_i}{\rho_i}} 
$$


Can improve upon that with the use of Rao-Blackwellization but computational complexity precludes use!



Sampoing wor approximate posterior

Importance Sampling vs Horivitz Thomposn estimator

Horivitz-Thompson:  sampling with replacement but us just the unique  labels




Fisher consistency. Rao-Blackewell. (DA -> RB ?)

completeness?

# several years later: 
Statistical Modelling Agency has ad out for help sampling models 

Circus statistician applies (admits they know are a bit intimidated about measuring human models, 

![ModelMatrix](img/model_agency.png)


neglicting to mention their failure with elephants ) 

Owner: oh silly  these are statistical models 
(oh says the statistian still eager for a job, not realizing that this was way more difficult)

# But reads up and discovers MCMC & BMA. 

Shicked and Appalled they discover that the standard approaches just use the Monte Carlo frequencies!  (meme - simpsons)

I've got this meme 

![I got this](https://tenor.com/view/trustme-yes-festivus-gif-18095876)


Using their knowledge of HT rediscovers the infamous harmonic mean estimator


in process discovered Nott & Kohn ACMC 
# adapt to Global Sampler

can't have the infinite regret of designing a "MCMC" algorithm to learn the sampling probabilities of how to 
avoid Hall of Mirrors (ie Bayes analysis of Bayes model based approach )

![Turtles](img/turtles_all_the_way_down.jpeg)

## advantages

fewer runs
escape locale modes ? vs Gibbs


## Successive Sampling

https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-43/issue-2/Asymptotic-Theory-for-Successive-Sampling-with-Varying-Probabilities-Without-Replacement/10.1214/aoms/1177692620.full

see adaptive normalized improvement Polson ref https://arxiv.org/pdf/2204.14121.pdf
improves over HT/Hajek.

## Basu's Elephants

bias as a bugaboo with IS/HT

Dumbo meme -> wrong model

review Ghosh recap; Rao-Blackewell

Bannerjee modern take https://arxiv.org/pdf/2306.10635.pdf  Justifies HT as Bayes 
Zio - Legacy of Basu https://link.springer.com/article/10.1007/s13171-023-00327-5

Little, R. (2022). Bayes, buttressed by design-based ideas, is the best overarching paradigm
for sample survey inference. Survey Methodology 48, 257â€“281. https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2022002/article/00001-eng.pdf?st=WfLlbHn8
Talk https://lshtm.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=e59d434e-f035-4f0e-b5f4-af5e00ca9772


Sanchez & Sanchez 2005 https://dl-acm-org.proxy.lib.duke.edu/doi/pdf/10.1145/1113316.1113320

## Model Based

log linear

Resolution V 2P -k designs

what do we get?

Sanchez & Sanchez 2005 https://dl-acm-org.proxy.lib.duke.edu/doi/pdf/10.1145/1113316.1113320


```{r}
require("mgcv")
#| eval: FALSE
des = FFdes(15)
des.bin = (des + 1)/2
```

```{r}
require("BAS")

```

```{r}
#| eval: FALSE
data(UScrime, package="MASS")
crime.bic <- bas.lm(log(y) ~ log(M) + So + log(Ed) +
  log(Po1) + log(Po2) +
  log(LF) + log(M.F) + log(Pop) + log(NW) +
  log(U1) + log(U2) + log(GDP) + log(Ineq) +
  log(Prob) + log(Time),
  data = UScrime, n.models = 2^15, prior = "g-prior", alpha = nrow(UScrime),
  modelprior = beta.binomial(1, 1),
  method = "deterministic")

model.space = which.matrix(crime.bic$which, crime.bic$n.vars)[,-1]
```


```{r}
#| eval: FALSE
ms.index = apply(model.space, 1, function(x)  paste0(as.character(x), collapse=""))
des.index = apply(des.bin, 1, function(x)  paste(as.character(x), collapse=""))
subsample = ms.index %in% des.index

```

```{r}
#| eval: FALSE
logm = crime.bic$logmarg[subsample]
df = data.frame(des)
df[] <- lapply( df, factor) 
df$logm = crime.bic$logmarg[subsample]
ff.fit = lm(logm ~ .^2, data=df)

```


## example under model of independence
log m = \mu + \sum(gamma)
## What Next

sequential sampling (design choice)

sampling + design

estimates (HT  or other). https://resources.environment.yale.edu/content/documents/00001669/Horvitz-Thompson.pdf

RB


# several years later: 
Statistical Modelling Agency has ad out for help sampling models 

Circus statistician applies (admits they know are a bit intimidated about measuring human models, 

![ModelMatrix](model_agency.png)


neglicting to mention their failure with elephants ) 

Owner: oh silly  these are statistical models 
(oh says the statistian still eager for a job, not realizing that this was way more difficult)

# But reads up and discovers MCMC & BMA. 

Shicked and Appalled they discover that the standard approaches just use the Monte Carlo frequencies!  (meme - simpsons)

I've got this meme 

![I got this](https://tenor.com/view/trustme-yes-festivus-gif-18095876)


Using their knowledge of HT rediscovers the infamous harmonic mean estimator


in process discovered Nott & Kohn ACMC 
# adapt to Global Sampler

can't have the infinite regret of designing a "MCMC" algorithm to learn the sampling probabilities of how to 
avoid Hall of Mirrors (ie Bayes analysis of Bayes model based approach )

![Turtles](turtles_all_the_way_down.jpeg)

## advantages

fewer runs
escape locale modes ? vs Gibbs


## Successive Sampling

https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-43/issue-2/Asymptotic-Theory-for-Successive-Sampling-with-Varying-Probabilities-Without-Replacement/10.1214/aoms/1177692620.full

see adaptive normalized improvement Polson ref https://arxiv.org/pdf/2204.14121.pdf
improves over HT/Hajek.
